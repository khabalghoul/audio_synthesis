# SÃ­ntesis audiorÃ­tmica en tiempo real con StyleGANâ€¯3

Este proyecto implementa un pipeline audiovisual que convierte audio en tiempo real proveniente de un sintetizador en imÃ¡genes generadas mediante StyleGAN3. El flujo del sistema es el siguiente:

```
Audio (JACK) â†’ audio_processor.py â†’ Vector latente â†’ server.py â†’ visualizer.py â†’ Imagen generada (StyleGAN3)
```

---

## ðŸš§ Requisitos previos

- **Hardware**: GPU NVIDIA compatible con CUDA â‰¥ 11.3  
- **Software de audio**: JACK (servidor de audio en tiempo real, por ejemplo usando `qjackctl`)
- **StyleGAN3**: https://github.com/NVlabs/stylegan3 (no es necesario pero si necesitamos poder correr el codigo de stylegan con todas sus dependencias, es la parte dificil)

**LibrerÃ­as Python requeridas**:

```bash
pip install numpy librosa jack-client torch torchvision torchaudio imgui matplotlib dnnlib
```

Se recomienda configurar StyleGAN3 previamente en un entorno virtual:


---

## ðŸ“‚ Estructura del repositorio

```
.
â”œâ”€â”€ audio_processor.py   # Captura de audio y generaciÃ³n del vector latente
â”œâ”€â”€ server.py            # ReenvÃ­o del vector latente vÃ­a TCP
â”œâ”€â”€ visualizer.py        # Interfaz visual que integra StyleGAN3
```

---

## EjecuciÃ³n del sistema

Ejecutar cada script en una terminal independiente, en el siguiente orden:

1. **Captura y procesamiento del audio**:

```bash
python audio_processor.py
```

2. **Servidor intermediario (reenviador TCP)**:

```bash
python server.py
```

3. **Visualizador  StyleGAN3**:

```bash
python visualizer.py
```
